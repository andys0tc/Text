{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Question duplicates\n",
    "Implementación de red siamesa aplicada a lenguaje natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/andrea/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.supervised import training\n",
    "from trax.fastmath import numpy as fastnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cargando datos\n",
    "Se usará un conjunto de datos con preguntas de Quora, este modelo resulta muy util para evitar que una pregunta similar sea posteada en el blog en repetidas ocasiones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question pairs:  404351\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"questions.csv\")\n",
    "N=len(data)\n",
    "print('Number of question pairs: ', N)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es necesario dividir el conjunto de datos en entrenamiento, validación y prueba"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloque\n"
     ]
    }
   ],
   "source": [
    "N_train = 300000\n",
    "N_test  = 10*1024\n",
    "print(\"bloque\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 300000 Test set: 10240\n"
     ]
    }
   ],
   "source": [
    "data_train = data[:N_train]\n",
    "data_test  = data[N_train:N_train+N_test]\n",
    "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
    "del(data) # remove to free memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para este problema sólo se seleccionarán las preguntas duplicadas para entrenar el modelo.\n",
    "Se construyen dos batches como entrada a la red Siamesa y se asume que la pregunta $$ q1_i $$ (pregunta $i$ en el primer batch) es el duplicado de $$q2_i$$, pero las restantes pregunta del batch no son duplicadas de $$q1_i$$\n",
    "\n",
    "Para el conjunto de prueba, se usa el par original de preguntas y estatus que describe si son o no duplicadas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate questions:  111486\n",
      "indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
     ]
    }
   ],
   "source": [
    "td_index = (data_train['is_duplicate'] == 1).to_numpy()\n",
    "td_index = [i for i, x in enumerate(td_index) if x]\n",
    "print('number of duplicate questions: ', len(td_index))\n",
    "print('indexes of first ten duplicate questions:', td_index[:10])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "is_duplicate:  1\n"
     ]
    }
   ],
   "source": [
    "print(data_train['question1'][5])  #  Example of question duplicates (first one in data)\n",
    "print(data_train['question2'][5])\n",
    "print('is_duplicate: ', data_train['is_duplicate'][5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para el entrenamiento solo se toman las preguntas duplicadas, de esta forma el generador puede regresar $$q1_i$$ y $$q2_i$$ duplicados si $i=k$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "Q1_train_words = np.array(data_train['question1'][td_index])\n",
    "Q2_train_words = np.array(data_train['question2'][td_index])\n",
    "\n",
    "Q1_test_words = np.array(data_test['question1'])\n",
    "Q2_test_words = np.array(data_test['question2'])\n",
    "y_test  = np.array(data_test['is_duplicate'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING QUESTIONS:\n",
      "\n",
      "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
      "\n",
      "Question 1:  What would a Trump presidency mean for current international master’s students on an F1 visa?\n",
      "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
      "\n",
      "TESTING QUESTIONS:\n",
      "\n",
      "Question 1:  How do I prepare for interviews for cse?\n",
      "Question 2:  What is the best way to prepare for cse? \n",
      "\n",
      "is_duplicate = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_train_words[0])\n",
    "print('Question 2: ', Q2_train_words[0], '\\n')\n",
    "print('Question 1: ', Q1_train_words[5])\n",
    "print('Question 2: ', Q2_train_words[5], '\\n')\n",
    "\n",
    "print('TESTING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_test_words[0])\n",
    "print('Question 2: ', Q2_test_words[0], '\\n')\n",
    "print('is_duplicate =', y_test[0], '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El siguiente paso es codificar cada palabra de entre los pares duplicados con un índice.\n",
    "Dada una pregunta, se codifica como una lista de números\n",
    "1. Tokenizar las preguntas con ```nltk.word_tokenize```\n",
    "2. Crear un diccionario que asigne 0 a las palabras que no se encuentren en el vocabulario\n",
    "3. Codificar cada palabra de las duplicadas con un índice"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#create arrays\n",
    "Q1_train = np.empty_like(Q1_train_words)\n",
    "Q2_train = np.empty_like(Q2_train_words)\n",
    "\n",
    "Q1_test = np.empty_like(Q1_test_words)\n",
    "Q2_test = np.empty_like(Q2_test_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the vocabulary is:  36268\n"
     ]
    }
   ],
   "source": [
    "# Building the vocabulary with the train set         (this might take a minute)\n",
    "from collections import defaultdict\n",
    "\n",
    "vocab = defaultdict(lambda: 0)\n",
    "vocab['<PAD>'] = 1\n",
    "\n",
    "for idx in range(len(Q1_train_words)):\n",
    "    Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])\n",
    "    Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\n",
    "    q = Q1_train[idx] + Q2_train[idx]\n",
    "    for word in q:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab) + 1\n",
    "print('The length of the vocabulary is: ', len(vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "6518\n"
     ]
    }
   ],
   "source": [
    "print(vocab['<PAD>'])\n",
    "print(vocab['Recognition'])\n",
    "print(vocab['Economy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "for idx in range(len(Q1_test_words)):\n",
    "    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n",
    "    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has reduced to:  111486\n",
      "Test set length:  10240\n"
     ]
    }
   ],
   "source": [
    "print('Train set has reduced to: ', len(Q1_train) )\n",
    "print('Test set length: ', len(Q1_test) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Convertir pregunta a tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "for i in range(len(Q1_train)):\n",
    "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\n",
    "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\n",
    "\n",
    "\n",
    "for i in range(len(Q1_test)):\n",
    "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n",
    "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first question in the train set:\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
      "\n",
      "encoded version:\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('first question in the train set:\\n')\n",
    "print(Q1_train_words[0], '\\n')\n",
    "print('encoded version:')\n",
    "print(Q1_train[0],'\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dividir datos Train/Val/Test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  111486\n",
      "The length of the training set is:   89188\n",
      "The length of the validation set is:  22298\n"
     ]
    }
   ],
   "source": [
    "cut_off = int(len(Q1_train)*.8)\n",
    "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
    "val_Q1, val_Q2 = Q1_train[cut_off: ], Q2_train[cut_off:]\n",
    "print('Number of duplicate questions: ', len(Q1_train))\n",
    "print(\"The length of the training set is:  \", len(train_Q1))\n",
    "print(\"The length of the validation set is: \", len(val_Q1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El generador de datos se asegura que el solo un par de preguntas se encuentre repetido y contra los demás pares no haya repetición"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
    "\n",
    "    input1 = []\n",
    "    input2 = []\n",
    "    idx = 0\n",
    "    len_q = len(Q1)\n",
    "    question_indexes = [*range(len_q)]\n",
    "\n",
    "    if shuffle:\n",
    "        rnd.shuffle(question_indexes)\n",
    "\n",
    "    while True:\n",
    "        if idx >= len_q:\n",
    "            idx = 0\n",
    "            if shuffle:\n",
    "                rnd.shuffle(question_indexes)\n",
    "\n",
    "        q1 = Q1[question_indexes[idx]]\n",
    "        q2 = Q2[question_indexes[idx]]\n",
    "\n",
    "        idx += 1\n",
    "        input1.append(q1)\n",
    "        input2.append(q2)\n",
    "        if len(input1) == batch_size:\n",
    "            max_len = max(max([len(inpt1) for inpt1 in input1]),max([len(inpt2) for inpt2 in input2]))\n",
    "            max_len = 2**int(np.ceil(np.log2(max_len)))\n",
    "            b1 = []\n",
    "            b2 = []\n",
    "            for q1, q2 in zip(input1, input2):\n",
    "                q1 = q1+[pad]*(max_len-len(q1))\n",
    "                q2 = q2+[pad]*(max_len-len(q2))\n",
    "                b1.append(q1)\n",
    "                b2.append(q2)\n",
    "            yield np.array(b1), np.array(b2)\n",
    "            input1, input2 = [], []  # reset the batches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First questions  :  \n",
      " [[   30    87   116   131    78   216   761    72   207    81    28  1871\n",
      "     72  2753  3327  2809 10102    21     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [   30    87   116    35  1099   292    21     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]] \n",
      "\n",
      "Second questions :  \n",
      " [[   30    87   116   131    78   216   761    72   207  2809 10102    21\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [   30    87   116    35  1099 20097    21 10849   292     4    64    78\n",
      "    111    17 13784 31860 22229   363    78  4717 25035  3616     1     1\n",
      "      1     1     1     1     1     1     1     1]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))\n",
    "print(\"First questions  : \",'\\n', res1, '\\n')\n",
    "print(\"Second questions : \",'\\n', res2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Modelo Siames\n",
    "Es una red neuronal la cual usa los mismos pesos mientras trabaja en a la par sobre dos vectores de entrada diferentes.\n",
    "\n",
    "El proceso es el siguiente:\n",
    "1. Llegan los embebidos de las preguntas duplicadas\n",
    "2. Pasan por una  capa LSTM\n",
    "3. Se normalizan\n",
    "4. Se usa un error triple para obtener la similitud coseno entre el par de preguntas\n",
    "\n",
    "El error triple utiliza una base que es comparado con la entrada positiva(real) y contra la falsa. La distancia de la base a la entrada positiva es minimizada y la distancia de la base a la negativa es maximizada\n",
    "\n",
    "\n",
    "$$\\mathcal{L}(A, P, N)=\\max \\left(\\|\\mathrm{f}(A)-\\mathrm{f}(P)\\|^{2}-\\|\\mathrm{f}(A)-\\mathrm{f}(N)\\|^{2}+\\alpha, 0\\right)$$\n",
    "\n",
    "$A$ es la entrada base, por ejemplo $q1_1$, $P$ la entrada duplicada,  $q2_1$, y $N$ la entrada negativa (la pregunta no duplicada), por ejemplo $q2_2$.<br>\n",
    "$\\alpha$ es un margen; una red segura, que tanto se quiere acercar los duplicados a los no duplicados.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "El modelo ocupa las siguientes capas\n",
    "* ```tl.Serial```: Secuencia de capas\n",
    "* ```tl.Embedding```: Mapeo de tokens dicretos a vector\n",
    "* ```tl.LSTM```: Capa LSTM\n",
    "* ```tl.Mean```: Calcula promedio a lo largo de un eje\n",
    "* ```tl.Fn```: Capa sin pesos y aplica función $f$\n",
    "* ```tl.parallel```: Aplica una lista de capas en paralelo a las entradas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Siamese(vocab_size=len(vocab), d_model=128, mode='train'):\n",
    "\n",
    "    def normalize(x):  # normalizes the vectors to have L2 norm 1\n",
    "        return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims=True))\n",
    "\n",
    "    q_processor = tl.Serial(  # Processor will run on Q1 and Q2.\n",
    "        tl.Embedding(vocab_size,d_model), # Embedding layer\n",
    "        tl.LSTM(d_model), # LSTM layer\n",
    "        tl.Mean(axis=1), # Mean over columns\n",
    "        tl.Fn('Normalize', lambda x: normalize(x))  # Apply normalize function\n",
    "    )  # Returns one vector of shape [batch_size, d_model].\n",
    "\n",
    "\n",
    "    model = tl.Parallel(q_processor, q_processor)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel_in2_out2[\n",
      "  Serial[\n",
      "    Embedding_41699_128\n",
      "    LSTM_128\n",
      "    Mean\n",
      "    Normalize\n",
      "  ]\n",
      "  Serial[\n",
      "    Embedding_41699_128\n",
      "    LSTM_128\n",
      "    Mean\n",
      "    Normalize\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "model = Siamese()\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Error Triple\n",
    "El error es compuesto por dos términos. Uno utiliza la media de todos los NO duplicados, el segundo utiliza el negativo más cercano. El error queda de la siguiente forma:\n",
    "\\begin{align}\n",
    " \\mathcal{Loss_1(A,P,N)} &=\\max \\left( -cos(A,P)  + mean_{neg} +\\alpha, 0\\right) \\\\\n",
    " \\mathcal{Loss_2(A,P,N)} &=\\max \\left( -cos(A,P)  + closest_{neg} +\\alpha, 0\\right) \\\\\n",
    "\\mathcal{Loss(A,P,N)} &= mean(Loss_1 + Loss_2) \\\\\n",
    "\\end{align}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def TripletLossFn(v1, v2, margin=0.25):\n",
    "\n",
    "    scores = fastnp.dot(v1,v2.T)  # pairwise cosine sim\n",
    "    batch_size = len(scores)\n",
    "    positive = fastnp.diag(scores)  # the positive ones (duplicates)\n",
    "    negative_without_positive = scores-2*fastnp.eye(batch_size)\n",
    "    closest_negative = negative_without_positive.max(axis=1)\n",
    "    negative_zero_on_duplicate = fastnp.multiply((1.0-fastnp.eye(batch_size)),scores)\n",
    "    mean_negative = fastnp.sum(negative_zero_on_duplicate,axis=1)/(batch_size - 1)\n",
    "    triplet_loss1 = fastnp.maximum(closest_negative-positive+margin,0)\n",
    "    triplet_loss2 = fastnp.maximum(0,mean_negative-positive+margin)\n",
    "    triplet_loss = fastnp.mean(triplet_loss1+triplet_loss2)\n",
    "\n",
    "\n",
    "    return triplet_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def TripletLoss(margin=0.25):\n",
    "    triplet_loss_fn = partial(TripletLossFn, margin=margin)\n",
    "    return tl.Fn('TripletLoss', triplet_loss_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenamiento\n",
    "Se define la función de costo y el optimizador"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_Q1.shape  (89188,)\n",
      "val_Q1.shape    (22298,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'])\n",
    "val_generator = data_generator(val_Q1, val_Q2, batch_size, vocab['<PAD>'])\n",
    "print('train_Q1.shape ', train_Q1.shape)\n",
    "print('val_Q1.shape   ', val_Q1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Entrenando modelo\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "lr_schedule = trax.lr.warmup_and_rsqrt_decay(400, 0.01)\n",
    "\n",
    "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# GRADED FUNCTION: train_model\n",
    "def train_model(Siamese, TripletLoss, lr_schedule,\n",
    "                train_generator=train_generator, val_generator=val_generator, output_dir='model/'):\n",
    "\n",
    "    output_dir = os.path.expanduser(output_dir)\n",
    "\n",
    "\n",
    "    train_task = training.TrainTask(\n",
    "        labeled_data=train_generator,       # Use generator (train)\n",
    "        loss_layer=TripletLoss(),         # Use triplet loss. Don't forget to instantiate this object\n",
    "        optimizer=trax.optimizers.Adam(0.01),          # Don't forget to add the learning rate parameter\n",
    "        lr_schedule=lr_schedule, # Use Trax multifactor schedule function\n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask(\n",
    "        labeled_data=val_generator,       # Use generator (val)\n",
    "        metrics=[TripletLoss()],          # Use triplet loss. Don't forget to instantiate this object\n",
    "    )\n",
    "\n",
    "\n",
    "    training_loop = training.Loop(Siamese(),\n",
    "                                  train_task,\n",
    "                                  eval_tasks=[eval_task],\n",
    "                                  output_dir=output_dir)\n",
    "\n",
    "    return training_loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/miniconda3/envs/pytorch/lib/python3.8/site-packages/jax/lib/xla_bridge.py:355: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n",
      "/home/andrea/miniconda3/envs/pytorch/lib/python3.8/site-packages/jax/lib/xla_bridge.py:368: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Total number of trainable weights: 5469056\n",
      "Step      1: Ran 1 train steps in 4.89 secs\n",
      "Step      1: train TripletLoss |  0.49999815\n",
      "Step      1: eval  TripletLoss |  0.49999839\n"
     ]
    }
   ],
   "source": [
    "train_steps = 5\n",
    "training_loop = train_model(Siamese, TripletLoss, lr_schedule)\n",
    "training_loop.run(train_steps)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluación"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading in the saved model\n",
    "model = Siamese()\n",
    "model.init_from_file('/media/andrea/Baba Yaga/BIGFOOT/CIC/PycharmProjects/PycharmProjects/semester work/Proy6/model.pkl.gz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clasificación\n",
    "\n",
    "Determinar la precisión del modelo. En el entrenamineto solo se usaron ejemplos positivos, en el caso del conjunto de prueba, tenemos parejas de preguntas de las cuales algunas son duplicadas y otas no. Pasarán por el modelo, se calculará la similitud coseno entre cada par y se fija un umbral para comparar si es o nó duplicado. El resultado se almacena acumulado en la precisión."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n",
    "\n",
    "    accuracy = 0\n",
    "    for i in range(0, len(test_Q1), batch_size):\n",
    "        q1, q2 = next(data_generator(test_Q1[i:i+batch_size], test_Q2[i:i+batch_size], batch_size, pad=vocab['<PAD>'], shuffle=False))\n",
    "        y_test = y[i:i+batch_size]\n",
    "        # Call the model\n",
    "        v1, v2 = model((q1,q2))\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            d = fastnp.dot(v1[j],v2[j].T)\n",
    "            res = d>threshold\n",
    "            accuracy += int(y_test[j]==res)\n",
    "    accuracy = accuracy / len(test_Q1)\n",
    "\n",
    "    return accuracy\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.69091796875\n"
     ]
    }
   ],
   "source": [
    "accuracy = classify(Q1_test,Q2_test, y_test, 0.7, model, vocab, batch_size = 512)\n",
    "print(\"Accuracy\", accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Probando con preguntas nuevas\n",
    "\n",
    "El modelo puede regresar 1 o 0 dependiendo si el par es una pregunta duplicada\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):\n",
    "    # use `nltk` word tokenize function to tokenize\n",
    "    q1 = nltk.word_tokenize(question1)  # tokenize\n",
    "    q2 = nltk.word_tokenize(question2)  # tokenize\n",
    "    Q1, Q2 = [], []\n",
    "    for word in q1:  # encode q1\n",
    "        Q1.append(vocab[word])\n",
    "    for word in q2:  # encode q2\n",
    "        Q2.append(vocab[word])\n",
    "\n",
    "    Q1, Q2 = next(data_generator([Q1], [Q2], batch_size=1, pad=vocab['<PAD>'], shuffle=False))\n",
    "    # Call the model\n",
    "    v1, v2 = model((Q1,Q2))\n",
    "    d = fastnp.dot(v1,v2.T)\n",
    "    res = d>threshold\n",
    "\n",
    "\n",
    "    if(verbose):\n",
    "        print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\n",
    "        print(\"d   = \", d)\n",
    "        print(\"res = \", res)\n",
    "\n",
    "    return res\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1  =  [[585  76   4  46  53  21   1   1]] \n",
      "Q2  =  [[ 676   33    4   46   53 7280   21    1]]\n",
      "d   =  [[0.6093261]]\n",
      "res =  [[ True]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "DeviceArray([[ True]], dtype=bool)"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1 = \"When will I see you?\"\n",
    "question2 = \"Where can I see you again?\"\n",
    "# 1 means it is duplicated, 0 otherwise\n",
    "predict(question1 , question2, 0.6, model, vocab, verbose = True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1  =  [[  443  1145  3159  1169    78 29017    21     1]] \n",
      "Q2  =  [[  443  1145    60 15302    28    78  7431    21]]\n",
      "d   =  [[0.47753587]]\n",
      "res =  [[False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "DeviceArray([[False]], dtype=bool)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to try with your own questions\n",
    "question1 = \"Do they enjoy eating the dessert?\"\n",
    "question2 = \"Do they like hiking in the desert?\"\n",
    "# 1 means it is duplicated, 0 otherwise\n",
    "predict(question1 , question2, 0.7, model, vocab, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}